{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import sqlite3\n",
    "import json\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Parse initial data from Wikipedia's highest-grossing films list\n",
    "url = \"https://en.wikipedia.org/wiki/List_of_highest-grossing_films\"\n",
    "response = requests.get(url)\n",
    "soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "# Find the first table (highest-grossing films)\n",
    "table = soup.find('table', {'class': 'wikitable'})\n",
    "\n",
    "# Initialize lists to store data\n",
    "titles = []\n",
    "years = []\n",
    "revenues = []\n",
    "directors = []\n",
    "countries = []\n",
    "\n",
    "# Parse table rows\n",
    "for row in table.find_all('tr')[1:]:  # Skip header row\n",
    "    cols = row.find_all(['td', 'th'])\n",
    "    if len(cols) >= 4:  # Ensure row has enough columns\n",
    "        # Extract title and get the film's Wikipedia link\n",
    "        title_cell = cols[2].find('i')\n",
    "        if title_cell:\n",
    "            title = title_cell.text.strip()\n",
    "            titles.append(title)\n",
    "            \n",
    "            # Extract year\n",
    "            year = cols[4].text.strip()\n",
    "            try:\n",
    "                year = int(year)\n",
    "            except ValueError:\n",
    "                try:\n",
    "                    year = int(year.split('-')[0])\n",
    "                except:\n",
    "                    year = None\n",
    "            years.append(year)\n",
    "            \n",
    "            # Extract revenue\n",
    "            revenue = cols[3].text.strip()\n",
    "            revenue = revenue.split('(')[0].strip()\n",
    "            revenues.append(revenue)\n",
    "\n",
    "            # Get the film's Wikipedia page link\n",
    "            film_link = title_cell.find('a')\n",
    "            if film_link:\n",
    "                film_href = \"https://en.wikipedia.org\" + film_link.get('href')\n",
    "                # Fetch the film's page\n",
    "                film_response = requests.get(film_href)\n",
    "                film_soup = BeautifulSoup(film_response.content, 'html.parser')\n",
    "                \n",
    "                # Find director(s)\n",
    "                director_row = film_soup.find('th', string=re.compile('Directed by'))\n",
    "                if director_row:\n",
    "                    director_data = director_row.find_next_sibling('td')\n",
    "                    film_directors = []\n",
    "                    if director_data:\n",
    "                        # Extract all director names\n",
    "                        for director in director_data.stripped_strings:\n",
    "                            if director not in ['[', ']', ',']:\n",
    "                                film_directors.append(director)\n",
    "                    directors.append(film_directors)\n",
    "                else:\n",
    "                    directors.append([])\n",
    "                \n",
    "                # Find country\n",
    "                country_row = film_soup.find('th', string=re.compile('Countr(y|ies)'))\n",
    "                if country_row:\n",
    "                    country_data = country_row.find_next_sibling('td')\n",
    "                    if country_data:\n",
    "                        # Handle both list and plain text formats\n",
    "                        country_list = country_data.find('ul')\n",
    "                        if country_list:\n",
    "                            # Get first country from list items\n",
    "                            first_li = country_list.find('li')\n",
    "                            if first_li:\n",
    "                                # Remove reference citations and clean up\n",
    "                                film_country = re.sub(r'\\[\\d+\\]', '', first_li.text).strip()\n",
    "                        else:\n",
    "                            # Handle plain text format\n",
    "                            film_country = re.sub(r'\\[\\d+\\]', '', country_data.text.strip().split(',')[0].split('\\n')[0]).strip()\n",
    "                    else:\n",
    "                        film_country = 'Unknown'\n",
    "                    countries.append(film_country)\n",
    "                else:\n",
    "                    countries.append('Unknown')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DataFrame\n",
    "df = pd.DataFrame({\n",
    "    'title': titles,\n",
    "    'release_year': years,\n",
    "    'box_office': revenues,\n",
    "    'directors': directors,\n",
    "    'country': countries\n",
    "})\n",
    "\n",
    "# Create SQLite database\n",
    "conn = sqlite3.connect('films.db')\n",
    "cursor = conn.cursor()\n",
    "\n",
    "# Create films table\n",
    "cursor.execute('''\n",
    "CREATE TABLE IF NOT EXISTS films (\n",
    "    id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
    "    title TEXT NOT NULL,\n",
    "    release_year INTEGER,\n",
    "    box_office TEXT,\n",
    "    director TEXT,\n",
    "    country TEXT\n",
    ")\n",
    "''')\n",
    "\n",
    "# Insert data into database\n",
    "for index, row in df.iterrows():\n",
    "    cursor.execute('''\n",
    "    INSERT INTO films (title, release_year, box_office, director, country)\n",
    "    VALUES (?, ?, ?, ?, ?)\n",
    "    ''', (row['title'], row['release_year'], row['box_office'], json.dumps(row['directors']), row['country']))\n",
    "\n",
    "conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export to JSON\n",
    "df.to_json('films.json', orient='records', indent=4)\n",
    "\n",
    "# Close database connection\n",
    "conn.close()\n",
    "\n",
    "print(\"Data successfully extracted, saved to database and exported to JSON!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
